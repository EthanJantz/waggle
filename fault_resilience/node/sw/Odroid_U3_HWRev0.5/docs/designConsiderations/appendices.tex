\appendix

\section{monit}

monit is a free, open source process supervision tool for Unix and Linux. \url{https://en.wikipedia.org/wiki/Monit}, \url{http://mmonit.com/monit/}

\url{http://mmonit.com/wiki/Monit/ConfigurationExamples}


\section{Collectl \& Colmux}

\subsection{Collectl}

From \url{http://collectl.sourceforge.net/}:  Unlike most monitoring tools that either focus on a small set of statistics, format their output in only one way, run either interatively or as a daemon but not both, collectl tries to do it all. You can choose to monitor any of a broad set of subsystems which currently include buddyinfo, cpu, disk, inodes, infiniband, lustre, memory, network, nfs, processes, quadrics, slabs, sockets and tcp. 

\subsubsection{Metrics}

\begin{itemize}
 \item Per CPU utilization
 \item Network traffic
\end{itemize}

\subsection{Colmux}

From  \url{http://collectl-utils.sourceforge.net/colmux.html} ``As its name implies, colmux is a collectl multiplexor, which allows one to collect data from multiple systems and treat it as a single data stream, essentially extending collectl's functionality to a set of hosts rather than a single one. Colmux has been tested on clusters of over 1000 nodes but one should also take note that this will put a heavier load on the system on which colmux is running. ``

\section{cpuset}
\tested{}


For more information see the following links:
\begin{itemize}
 \item \url{https://www.kernel.org/doc/Documentation/cgroups/cpusets.txt}
 \item \url{https://www.suse.com/documentation/slerte_11/slerte_tutorial/data/slerte_tutorial.html}
 \item \url{http://techpubs.sgi.com/library/tpl/cgi-bin/getdoc.cgi?coll=linux&db=bks&srch=&fname=/SGI_Admin/LX_Resource_AG/sgi_html/ch01.html}
\end{itemize}

\subsection{Install}

The cgroups are redesigned as of 2013, we may consider going in more recent versions of the Linux kernel, 3.15 or 3.16, to see what new things may be available.

\begin{verbatim}
General setup  --->
[*] Control Group support  --->
--- Control Group support
[ ]   Example debug cgroup subsystem
[ ]   Freezer cgroup subsystem
[*]   Device controller for cgroups                                                                 
[*]   Cpuset support                                                                                
[*]     Include legacy /proc/<pid>/cpuset file                                                      
[*]   Simple CPU accounting cgroup subsystem                                                        
[ ]   Resource counters
- -     Memory Resource Controller for Control Groups
- -       Memory Resource Controller Swap Extension
- -         Memory Resource Controller Swap Extension enabled by default
- -       Memory Resource Controller Kernel Memory accounting (EXPERIMENTAL)
- -     HugeTLB Resource Controller for Control Groups
[ ]   Enable perf\_event per-cpu per-container group (cgroup) monitoring
[*]   Group CPU scheduler  --->
[ ]   Block IO controller
- -     Enable Block IO controller debugging
\end{verbatim}


From man page: ``If a system supports cpusets, then it will have the entry \textit{nodev cpuset} in the file /proc/filesystems''.

\begin{lstlisting}
# cat /proc/filesystems | grep cpuset
\end{lstlisting}

\textbf{There is a way to restrict all process to the cpuset and it happens using bootcpuset. I could not find it, however it may be possible through the init= boot argument}


\subsubsection{User-level control application}
apt-get instal cpuset

\subsection{cgroups filesystem}
\url{https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-cpu.html}

\begin{lstlisting}
mount -t cgroup cgroup /sys/fs/cgroup
\end{lstlisting}

\subsection{Creating a Set}

\begin{lstlisting}
cset set --cpu=2-4 --mem=0 --set=<SET_NAME>
\end{lstlisting}


\subsection{Adding a Process to a Set}

\begin{lstlisting}
cset proc --set <SET_NAME> --exec -- <APP> <APP_ARGS> & 
\end{lstlisting}

\subsection{Upstart Init Configuration}


\section{Stress Testing}

\subsection{CPU}

\begin{tabular}{| l | c | c | c |}
\hline
 Stress Test Suite & Active Cores & CPU Utilization & Ampere \\
\hline
\hline
 U-Boot (pre-boot) & 0 & 0 & 0.248 \\
\hline
 Idle (post-boot)  & 0 & 0 & 0.330\\
\hline
 \multirow{4}{*}{stress-ng} & 1 & 100 & 0.440\\
  & 2 & 100 & 0.550  \\
  & 3 & 100 & 0.665  \\
  & 4 & 100 & 0.795  \\
\hline
 \multirow{4}{*}{stress-py} & 1 & 100 & 0.510\\
  & 2 & 100 & 0.705  \\
  & 3 & 100 & 0.940  \\
  & 4 & 100 & 1.230  \\
\hline
\end{tabular}

The difference between \textit{stress-ng}\cite{stress-ng} and \textit{stress-py}\cite{stress-py} is probably due to utilization of the floating point functional units with \textit{stress-py}.

\subsection{Network}

To stress the ethernet controller we are using \textit{iperf}\cite{iperf}. In all stress cases the CPU utilization reaches 100%. To generate different stress utilization we exercise the tcp window size from 1k to 20k.


\begin{tabular}{| l | c | c | c |}
\hline
 Cable & TCP window size & Ampere & CPU Utilization \\
\hline
\hline
 \multirow{6}{*}{Default} & 1k & 0.340 & \\
  & 2k & 0.410 & \\
  & 4k & 0.455 & \\
  & 8 & 0.495 & \\
  & 16 & 0.535 & \\
  & (auto) & 0.565 & \\
\hline
 \multirow{6}{*}{Cable 2} & 1k & & \\
  & 2k & & \\
  & 4k & & \\
  & 8 & & \\
  & 16 & & \\
  & (auto) & & \\
\hline
\end{tabular}


\subsection{Memory}

\section{Communication Resilience}
\tested{}

We will be using netem to emulate different network conditions. \textit{netem} ``provides Network Emulation functionality for testing protocols by emulating the properties of wide area networks.'' \cite{netem}

\noindent
Resources:
\begin{itemize}
 \item \url{http://www.linuxfoundation.org/collaborate/workgroups/networking/netem}
 \item \url{http://www.opensourceforu.com/2012/06/bandwidth-throttling-netem-network-emulation/}
 \item \url{https://calomel.org/network_loss_emulation.html}
\end{itemize}

\subsection{Install}

Enable the kernel module (version $>=$ 2.6)

\begin{verbatim}
Networking -->
 Networking Options -->
  QoS and/or fair queuing -->
   Network emulator
\end{verbatim}

\subsection{Use}

General options:
\begin{verbatim}
Usage: ... netem [ limit PACKETS ] 
                 [ delay TIME [ JITTER [CORRELATION]]]
                 [ distribution {uniform|normal|pareto|paretonormal} ]
                 [ drop PERCENT [CORRELATION]] 
                 [ corrupt PERCENT [CORRELATION]] 
                 [ duplicate PERCENT [CORRELATION]]
                 [ reorder PRECENT [CORRELATION] [ gap DISTANCE ]]
\end{verbatim}

\subsubsection{Examples}

\noindent
Delete queue discipline from interface:
\begin{lstlisting}
tc qdisc del dev eth0 root
\end{lstlisting}

\noindent
Change the loss rate on the queue discipline of an interface
\begin{lstlisting}
tc qdisc change dev eth0 root netem loss 0.1%
\end{lstlisting}

\noindent
Change the duplicate/corruption rate on the queue discipline of an interface
\begin{lstlisting}
tc qdisc change dev eth1 root netem duplicate/corrupt 1%
\end{lstlisting}

\noindent
Add a constant delay and jitter to the queue discipline of an interface
\begin{lstlisting}
tc qdisc add dev eth1 root netem delay 80ms 10ms
\end{lstlisting}


\section{Linux Kernel}

Resources:
\begin{itemize}
 \item [3.16] https://github.com/dsd/linux-odroid/
 \item [3.8] https://github.com/hardkernel/linux
\end{itemize}

\subsection{Compile}

\begin{lstlisting}
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- 
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- uImage modules exynos4412-smdk4412.dtb
\end{lstlisting}

\begin{lstlisting}
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- odroidu2_defconfig
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- menuconfig
<Enable Custom Options> ...
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- zImage
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- modules
LOADADDR=40008000 make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- uImage
\end{lstlisting}

\subsection{Install}

\begin{lstlisting}
cp arch/arm/boot/zImage /media/boot/
cp .config /media/rootfs/boot/config-`cat ./include/config/kernel.release`
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- modules_install INSTALL_MOD_PATH=/media/rootfs/
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- firmware_install INSTALL_FW_PATH=/media/rootfs/lib/firmware
\end{lstlisting}

\section{U-Boot}

Resources:
\begin{itemize}
 \item mainline
\end{itemize}

\subsection{Compile}

\begin{lstlisting}
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- odroid_config
make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- -j 2 all
\end{lstlisting}

\subsection{Install}

Then we need to use 'u-boot-dtb.bin'.

\textbf{PUT EXAMPLE BOOT.SCR HERE}

%% ## Copy boot scripts

%% use
%% https://repo.anl-external.org/repos/cerisc/forest/branches/2014/getziadz/code/sdcardTools/dummyBoot/

%% copy the boot.* files 



\section{Upstart}

\url{http://fog.ccsf.edu/~gboyd/cs260a/online/startup/upstart.html}

\section{Creating an Image}

\begin{enumerate}
 \item Complile UBoot
 \item Compile Kernel
 \item Format SDCard
 \item Flush boot binaries to SDCard
 \item Get rootfs
 \item copy rootfs to SDCard
 \item Install Kernel, boot.scr, and btd to SDCard
 \item Configure /etc files
 \item Install extra packages
\end{enumerate}

\subsection{Format SDCard}

Using the following script type: \texttt{./mkcardOdroid.sh /dev/<sd\_card\_device>}
\lstinputlisting{data/mkcardOdroid.sh}

\subsubsection{Flush Bootloader binaries in SDCard}

Using the following script type: \texttt{./sd\_fusing.sh /dev/<sd\_card\_device>}
\lstinputlisting{data/sd_fusing.sh}

\subsection{Populate the rootfs partition}

There are two way to populate the rootfs partition: the fastest and easiest way is to download the rootfs provided by the linaro, the second way is to start from scratch and using live-build, bootstrap, or multistrap generate and configure a custom rootfs. The second option is laborious but provides significant flexibility and should be seriously considered. To get the latest rootfs from linaro use the following command:

\begin{lstlisting}
wget -r --no-parent -P latest http://snapshots.linaro.org/ubuntu/images/nano/latest/
\end{lstlisting}

and then uncompress and copy the content of the 'binary' folder to the rootfs partitions you generated on the SDCard.

\subsection{Linux Kernel}

See the above \textit{Kernel} subsection.

\subsection{U-Boot}

See above \textit{U-Boot} subsection.

\subsection{Configure /etc}

\subsubsection{Networking}

We need to edit /etc/network/interfaces so that ethernet is brought up at boot time and IPs are assigned from dhcp

\begin{lstlisting}
++ auto eth0 eth1
++ iface eth0 inet dhcp
++ iface eth1 inet dhcp
\end{lstlisting}

In addition a permanent solution should be found about the MAC problem. The MAC is autogenerated at first boot and saved into a file, this creates problems when using image cloning to generate new SDCards.


\subsubsection{Extra Packages}

On the first boot run the following command sequence to install required packages.
\begin{lstlisting}
apt-get update
# Enable remote logins
apt-get install openssh-server
# Required by waggle code
apt-get install python-pika 
# For editing
apt-get install nano
\end{lstlisting}

\noindent
\textit{After installing openssh follow the instructions on the security chapter to restrict its access}

\subsubsection{Other}

After the first boot a new password should be setup.

We may also create a new user that will be responsible for running the majority of the waggle code.

\section{Known Issues}

\subsection{Clock}

The clock resets after power lose.
\begin{itemize}
 \item \url{http://www.hardkernel.com/main/products/prdt_info.php?g_code=G137508214939}
 \item \url{http://forum.odroid.com/download/file.php?mode=view&id=92}
\end{itemize}

\subsection{MAC Address}

The MAC address is generated at first boot. If a single image is used to flash all nodes this will cause all nodes to have the same MAC address.


\section{The Node Controller Buffer}

Why we chose to have a buffer between the internal and external communication.

\subsection{Python Manager Implementation}

From \url{https://docs.python.org/2/library/multiprocessing.html#managers}: Managers provide a way to create data which can be shared between different processes. A manager object controls a server process which manages shared objects. Other processes can access the shared objects by using proxies.

\subsubsection{Advantages}

\subsubsection{Disadvantages}

Slower than shared memory.

\subsubsection{Tests}

\lstinputlisting{data/manager/server.py}
\lstinputlisting{data/manager/client.py}

\begin{tabular}{| l | c | c |}
\hline
\multicolumn{3}{|c|}{Memory Benchmark} \\
\hline
Number of 1024B Entries & VIRT &  RES\\
\hline
\hline
1M & \multicolumn{2}{|c|}{Out of Memory} \\
\hline
100K & 132M & 112M\\ 
\hline
10K & 38M & 17M\\ 
\hline
1K & 28M & 7M\\ 
\hline
\end{tabular}

